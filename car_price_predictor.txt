# Car Price Predictor Project | Machine Learning | Linear Regression

import pandas as pd
import numpy as np 

car=pd.read_csv("C:\\Users\\ojhas\\Dropbox\\PC\\Downloads\\quikr_car.csv")
print(car) 
print(car.shape)
print(car.info())

# üîç Data Quality Issues & Cleaning Steps

# Year Column: Contains non-year values and Convert from object to integer.

# Price Column: Contains Ask for Price instead of numeric values and Convert from object to integer after cleaning.

# Kms Driven Column: Includes non-integer values mixed with text ("kms") and Convert from object to integer after extraction.

# Missing Values: kms_driven has missing (NaN) values and fuel_type contains NaN values.

# Name Column: Retain only the first 3 words for simplification.

# Data Cleaning

backup=car.copy()

car=car[car['year'].str.isnumeric()]
car['year']=car['year'].astype('int32')
print(car.info())

car=car[car['Price'] != "Ask For Price"]
car['Price']=car['Price'].str.replace(',','').astype('int32')
print(car.info())

car['kms_driven']=car['kms_driven'].str.split(' ').str.get(0).str.replace(',','')
car=car[car['kms_driven'].str.isnumeric()]
car['kms_driven']=car['kms_driven'].astype('int32')
print(car.info())

car=car[~car['fuel_type'].isna()]
print(car.info())

car['name']=car['name'].str.split(' ').str.slice(0,3).str.join(' ')
car=car.reset_index(drop=True)
print(car)

# Remove outlier

car=car[car['Price']<6e6].reset_index(drop=True)
print(car.info())

# Store clean data into other csv file

car.to_csv("clean_car.csv")
print(pd.read_csv("clean_car.csv"))

# Model creation

x=car.drop(columns='Price')
y=car['Price']

# Train and Test the dataset

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.metrics import r2_score

# Creating an OneHotEncoder object to contain all the possible categories

ohe=OneHotEncoder()
ohe.fit(x[['name','company','fuel_type']])

# Creating a column transformer to transform categorical columns
column_trans=make_column_transformer((OneHotEncoder(categories=ohe.categories_),['name','company','fuel_type']),
                                    remainder='passthrough')
# Linear Regression Model

lr=LinearRegression()

# Making a pipeline

pipe=make_pipeline(column_trans,lr)

# Fitting the model

pipe.fit(x_train,y_train)

y_pred=pipe.predict(x_test)

# Checking R2 Score

r2_score(y_test,y_pred)

# Finding the model with a random state of TrainTestSplit where the model was found to give almost 0.92 as r2_score

scores=[]
for i in range(1000):
    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=i)
    lr=LinearRegression()
    pipe=make_pipeline(column_trans,lr)
    pipe.fit(x_train,y_train)
    y_pred=pipe.predict(x_test)
    scores.append(r2_score(y_test,y_pred))

np.argmax(scores)

scores[np.argmax(scores)]

# The best model is found at a certain random state

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=np.argmax(scores))
lr=LinearRegression()
pipe=make_pipeline(column_trans,lr)
pipe.fit(x_train,y_train)
y_pred=pipe.predict(x_test)
r2_score(y_test,y_pred)

import pickle
pickle.dump(pipe,open('LinearRegressionModel.pkl','wb'))
ans=pipe.predict(pd.DataFrame(columns=['name','company','year','kms_driven','fuel_type'],data=np.array(['Maruti Suzuki Swift','Maruti',2019,100,'Petrol']).reshape(1,5)))
print(ans)





